{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: Analyzing Metadata of Hugging Face Models\n",
    "\n",
    "#### Introduction\n",
    " Hugging Face provides a wide variety of machine learning models that can be used in diverse domains. \n",
    " In this notebook, we analyze metadata of models available on Hugging Face Hub. \n",
    " Specifically, we will retrieve metadata such as download counts, parameters, release dates, and licenses, \n",
    " and organize the data for insights.\n",
    "\n",
    "#### Required Libraries\n",
    " We use the `huggingface_hub` library to interact with the Hugging Face Hub API and `pandas` for data manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import huggingface_hub\n",
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import concurrent.futures\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize the Hugging Face API\n",
    " The HfApi class is used to interact with the Hugging Face Hub API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fetch OK. Number of models fetched: 1320778\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "hugging_face_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if hugging_face_token is None:\n",
    "    raise ValueError(\n",
    "        \"HF_TOKEN not found in .env file or environment variables.\"\n",
    "        \" Make sure you have a line like HF_TOKEN=your_hf_token in your .env.\"\n",
    "    )\n",
    "\n",
    "api = HfApi(token=hugging_face_token)\n",
    "\n",
    "# Test the API (fetch a small sample of models)\n",
    "try:\n",
    "    # Convert the generator to a list directly\n",
    "    test_models = list(api.list_models())\n",
    "    print(f\"Test fetch OK. Number of models fetched: {len(test_models)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching test models: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fetch Model Metadata\n",
    " We fetch metadata for a large number of public models from the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1321287 models.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Adjust limit as you wish. 'full=True' may or may not work on older versions.\n",
    "    all_models = list(api.list_models(full=True))\n",
    "    print(f\"Fetched {len(all_models)} models.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching models: {e}\")\n",
    "    all_models = []\n",
    "\n",
    "# If no models were fetched, we can't proceed further\n",
    "if not all_models:\n",
    "    print(\"No models available. Exiting.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Metadata Extraction Rules\n",
    " We use regular expressions to extract parameter patterns (e.g., \"82M\", \"3.5B\") from model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_pattern = re.compile(r\"(\\d+(\\.\\d+)?[MBmb])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Process Models to Extract Metadata\n",
    " For each model, we retrieve detailed metadata and organize it into a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing model bytedance-research/UI-TARS-7B-gguf: 404 Client Error. (Request ID: Root=1-679223ad-68b1aa0077655fbf1a34816f;628b5935-c68d-4426-ad0e-bf1b943b0dc0)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/api/models/bytedance-research/UI-TARS-7B-gguf.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "model_metadata_list = []\n",
    "param_pattern = re.compile(r\"\\d+(\\.\\d+)?[mMbB]\")\n",
    "\n",
    "# Define the number of models for which we want detailed info\n",
    "detailed_info_count = 100\n",
    "\n",
    "for index, model in enumerate(all_models):\n",
    "    try:\n",
    "        model_id = model.modelId\n",
    "\n",
    "        # For the first 100 models, fetch detailed information\n",
    "        if index < detailed_info_count:\n",
    "            model_info = api.model_info(model_id)\n",
    "\n",
    "            # Safely extract license and last_updated\n",
    "            card_data = model_info.cardData if model_info.cardData else {}\n",
    "            license_info = card_data.get(\"license\", \"Unknown\")  # Use get() to avoid KeyError\n",
    "            last_updated = str(model_info.lastModified) if model_info.lastModified else \"Unknown\"\n",
    "        else:\n",
    "            # Set defaults for the remaining models\n",
    "            license_info = \"Unknown\"\n",
    "            last_updated = \"Unknown\"\n",
    "\n",
    "        # Extract parameters\n",
    "        match = param_pattern.search(model_id)\n",
    "        if match:\n",
    "            param_candidate = match.group(0)\n",
    "            if param_candidate.lower().endswith(\"m\"):\n",
    "                parameters = f\"{float(param_candidate[:-1]) / 1000:.3f}B\"\n",
    "            elif param_candidate.lower().endswith(\"b\"):\n",
    "                parameters = param_candidate\n",
    "            else:\n",
    "                parameters = \"Unknown\"\n",
    "        else:\n",
    "            parameters = \"Unknown\"\n",
    "\n",
    "        # Add model metadata to the list\n",
    "        metadata = {\n",
    "            \"model_id\": model_id,\n",
    "            \"downloads (M)\": model_info.downloads / 1_000_000 if index < detailed_info_count and model_info.downloads else 0,\n",
    "            \"parameters\": parameters,\n",
    "            \"last_updated\": last_updated,\n",
    "            \"license\": license_info,\n",
    "        }\n",
    "        model_metadata_list.append(metadata)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(f\"Error fetching metadata for model {model_id}: {e}\")\n",
    "        metadata = {\n",
    "            \"model_id\": model_id,\n",
    "            \"downloads (M)\": 0,\n",
    "            \"parameters\": \"Unknown\",\n",
    "            \"last_updated\": \"Unknown\",\n",
    "            \"license\": \"Unknown\",\n",
    "        }\n",
    "        model_metadata_list.append(metadata)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing model {model_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Organize Metadata into a DataFrame\n",
    " The metadata list is converted into a pandas DataFrame for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1321286\n",
      "\n",
      "DataFrame created with 1321286 entries.\n",
      "DataFrame columns: ['model_id', 'downloads (M)', 'parameters', 'last_updated', 'license']\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(model_metadata_list)\n",
    "print(len(model_metadata_list))\n",
    "print(f\"\\nDataFrame created with {len(df)} entries.\")\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "\n",
    "# Sort by downloads (M) if available\n",
    "if \"downloads (M)\" in df.columns:\n",
    "    df.sort_values(by=\"downloads (M)\", ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.index += 1\n",
    "else:\n",
    "    print(\"Warning: 'downloads (M)' column is missing; skipping sort.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Display the DataFrame\n",
    " The complete DataFrame is displayed to view all rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 models by 'downloads (M)':\n",
      "                                    model_id  downloads (M) parameters               last_updated     license\n",
      "1              google-bert/bert-base-uncased      75.484575    Unknown  2024-02-19 11:06:12+00:00  apache-2.0\n",
      "2     sentence-transformers/all-MiniLM-L6-v2      74.605162    Unknown  2024-11-01 10:26:30+00:00  apache-2.0\n",
      "3                      openai-community/gpt2      12.553279    Unknown  2024-02-19 10:57:45+00:00         mit\n",
      "4           pyannote/speaker-diarization-3.1       8.931313    Unknown  2024-05-10 19:43:23+00:00         mit\n",
      "5           meta-llama/Llama-3.1-8B-Instruct       5.388887         8B  2024-09-25 17:00:57+00:00    llama3.1\n",
      "6                    openai/whisper-large-v3       4.931610    Unknown  2024-08-12 10:20:10+00:00  apache-2.0\n",
      "7                answerdotai/ModernBERT-base       4.708041    Unknown  2025-01-15 20:11:48+00:00  apache-2.0\n",
      "8   meta-llama/Llama-3.2-11B-Vision-Instruct       2.555887        11B  2024-12-04 01:35:48+00:00    llama3.2\n",
      "9         mistralai/Mistral-7B-Instruct-v0.3       2.309432         7B  2024-08-21 12:18:25+00:00  apache-2.0\n",
      "10             openai/whisper-large-v3-turbo       2.300918    Unknown  2024-10-04 14:51:11+00:00         mit\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"\\nTop 10 models by 'downloads (M)':\")\n",
    "print(df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the DataFrame for Offline Analysis\n",
    " The metadata is saved to a CSV file for further offline analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata saved to huggingface_model_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"huggingface_model_metadata.csv\")\n",
    "print(\"\\nMetadata saved to huggingface_model_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    " In this notebook, we successfully fetched metadata from the Hugging Face Hub. \n",
    " The data is organized into a pandas DataFrame and includes information such as downloads, parameters, \n",
    " last updated date, and license type. The metadata was sorted by download counts to identify the most popular models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
